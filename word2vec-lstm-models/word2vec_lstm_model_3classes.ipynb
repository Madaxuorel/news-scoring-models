{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gensim\n",
      "  Downloading gensim-4.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.5 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.5/26.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting smart-open>=1.8.1\n",
      "  Downloading smart_open-7.0.4-py3-none-any.whl (61 kB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 KB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.18.5 in /home/adam/.local/lib/python3.10/site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /home/adam/.local/lib/python3.10/site-packages (from gensim) (1.10.1)\n",
      "Requirement already satisfied: wrapt in /home/adam/.local/lib/python3.10/site-packages (from smart-open>=1.8.1->gensim) (1.14.1)\n",
      "Installing collected packages: smart-open, gensim\n",
      "Successfully installed gensim-4.3.2 smart-open-7.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 17:20:17.230832: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-29 17:20:17.637745: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-29 17:20:17.641062: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-29 17:20:19.278224: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import gensim\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DOWNLOAD WORD2VEC PRE-TRAINED EMBEDDING AT  https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?resourcekey=0-wjGZdNAUop6WykTtMip30g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "word2vec_path = 'GoogleNews-vectors-negative300.bin'\n",
    "word2vec_model = gensim.models.KeyedVectors.load_word2vec_format(word2vec_path, binary=True)\n",
    "print(f'Found {len(word2vec_model.key_to_index)} word vectors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../preprocessing/all-data-processed-3classes.csv\")\n",
    "data[\"Clean sentences\"] = data[\"Clean sentences\"].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"Clean sentences\"], data[\"Sentiment\"], test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = len(token.index_word) + 1\n",
    "X_train = token.texts_to_sequences(X_train)\n",
    "X_test = token.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 47\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_labels = np.array(y_train)  # Convert to NumPy array if not already\n",
    "y_test_labels = np.array(y_test)  # Convert to NumPy array if not already\n",
    "\n",
    "y_train = np.where(y_train_labels == -1, 0, y_train_labels)\n",
    "y_train = np.where(y_train_labels == 0, 1, y_train)\n",
    "y_train = np.where(y_train_labels == 1, 2, y_train)\n",
    "\n",
    "y_test = np.where(y_test_labels == -1, 0, y_test_labels)\n",
    "y_test = np.where(y_test_labels == 0, 1, y_test)\n",
    "y_test = np.where(y_test_labels == 1, 2, y_test)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_dim = 300  # Size of Word2Vec embeddings\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((vocab, embedding_dim))\n",
    "for word, i in token.word_index.items():\n",
    "    if i < vocab:\n",
    "        if word in word2vec_model:\n",
    "            embedding_vector = word2vec_model[word]\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 17:21:44.829300: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-29 17:21:44.831098: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-29 17:21:44.832653: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 47, 300)           8724600   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 47, 128)           219648    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 47, 128)           0         \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 3)                 195       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 8,993,851\n",
      "Trainable params: 269,251\n",
      "Non-trainable params: 8,724,600\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 17:21:45.050538: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-29 17:21:45.052294: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-29 17:21:45.053512: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    }
   ],
   "source": [
    "vec_size = 300  # Word2Vec embedding size\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab, vec_size, weights=[embedding_matrix], input_length=MAX_SEQUENCE_LENGTH, trainable=False))\n",
    "model.add(LSTM(128, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(3, activation='softmax'))  # Output layer with softmax activation\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model_lstm.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Define a learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 5:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * 0.9\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 17:21:56.706165: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-29 17:21:56.707897: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-29 17:21:56.709064: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-05-29 17:21:56.883676: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-29 17:21:56.884839: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-29 17:21:56.885937: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-05-29 17:21:57.848523: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-29 17:21:57.850444: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-29 17:21:57.852268: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-05-29 17:21:58.049093: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-29 17:21:58.051574: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-29 17:21:58.053586: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896/897 [============================>.] - ETA: 0s - loss: 0.9252 - accuracy: 0.5425"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 17:22:56.981124: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-29 17:22:56.982616: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-29 17:22:56.983625: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-05-29 17:22:57.139507: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-29 17:22:57.140979: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-29 17:22:57.142304: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "897/897 [==============================] - 63s 67ms/step - loss: 0.9251 - accuracy: 0.5425 - val_loss: 0.8518 - val_accuracy: 0.6119 - lr: 1.0000e-04\n",
      "Epoch 2/40\n",
      "897/897 [==============================] - 59s 66ms/step - loss: 0.7280 - accuracy: 0.6949 - val_loss: 0.6903 - val_accuracy: 0.7176 - lr: 1.0000e-04\n",
      "Epoch 3/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.6494 - accuracy: 0.7360 - val_loss: 0.6589 - val_accuracy: 0.7352 - lr: 1.0000e-04\n",
      "Epoch 4/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.6128 - accuracy: 0.7543 - val_loss: 0.6252 - val_accuracy: 0.7531 - lr: 1.0000e-04\n",
      "Epoch 5/40\n",
      "897/897 [==============================] - 59s 66ms/step - loss: 0.5787 - accuracy: 0.7732 - val_loss: 0.6143 - val_accuracy: 0.7540 - lr: 1.0000e-04\n",
      "Epoch 6/40\n",
      "897/897 [==============================] - 59s 65ms/step - loss: 0.5406 - accuracy: 0.7913 - val_loss: 0.5850 - val_accuracy: 0.7719 - lr: 9.0000e-05\n",
      "Epoch 7/40\n",
      "897/897 [==============================] - 59s 66ms/step - loss: 0.5025 - accuracy: 0.8093 - val_loss: 0.5550 - val_accuracy: 0.7829 - lr: 8.1000e-05\n",
      "Epoch 8/40\n",
      "897/897 [==============================] - 59s 66ms/step - loss: 0.4630 - accuracy: 0.8285 - val_loss: 0.5168 - val_accuracy: 0.8026 - lr: 7.2900e-05\n",
      "Epoch 9/40\n",
      "897/897 [==============================] - 58s 65ms/step - loss: 0.4307 - accuracy: 0.8437 - val_loss: 0.5358 - val_accuracy: 0.8033 - lr: 6.5610e-05\n",
      "Epoch 10/40\n",
      "897/897 [==============================] - 58s 65ms/step - loss: 0.3974 - accuracy: 0.8578 - val_loss: 0.4749 - val_accuracy: 0.8249 - lr: 5.9049e-05\n",
      "Epoch 11/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.3723 - accuracy: 0.8706 - val_loss: 0.4446 - val_accuracy: 0.8393 - lr: 5.3144e-05\n",
      "Epoch 12/40\n",
      "897/897 [==============================] - 59s 66ms/step - loss: 0.3473 - accuracy: 0.8801 - val_loss: 0.4542 - val_accuracy: 0.8378 - lr: 4.7830e-05\n",
      "Epoch 13/40\n",
      "897/897 [==============================] - 58s 65ms/step - loss: 0.3265 - accuracy: 0.8903 - val_loss: 0.4167 - val_accuracy: 0.8500 - lr: 4.3047e-05\n",
      "Epoch 14/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.3076 - accuracy: 0.8998 - val_loss: 0.4001 - val_accuracy: 0.8610 - lr: 3.8742e-05\n",
      "Epoch 15/40\n",
      "897/897 [==============================] - 61s 68ms/step - loss: 0.2933 - accuracy: 0.9057 - val_loss: 0.3929 - val_accuracy: 0.8682 - lr: 3.4868e-05\n",
      "Epoch 16/40\n",
      "897/897 [==============================] - 61s 68ms/step - loss: 0.2816 - accuracy: 0.9092 - val_loss: 0.3870 - val_accuracy: 0.8660 - lr: 3.1381e-05\n",
      "Epoch 17/40\n",
      "897/897 [==============================] - 61s 68ms/step - loss: 0.2668 - accuracy: 0.9145 - val_loss: 0.3694 - val_accuracy: 0.8795 - lr: 2.8243e-05\n",
      "Epoch 18/40\n",
      "897/897 [==============================] - 61s 68ms/step - loss: 0.2569 - accuracy: 0.9200 - val_loss: 0.3547 - val_accuracy: 0.8833 - lr: 2.5419e-05\n",
      "Epoch 19/40\n",
      "897/897 [==============================] - 61s 68ms/step - loss: 0.2467 - accuracy: 0.9246 - val_loss: 0.3527 - val_accuracy: 0.8808 - lr: 2.2877e-05\n",
      "Epoch 20/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.2401 - accuracy: 0.9266 - val_loss: 0.3622 - val_accuracy: 0.8801 - lr: 2.0589e-05\n",
      "Epoch 21/40\n",
      "897/897 [==============================] - 59s 66ms/step - loss: 0.2328 - accuracy: 0.9304 - val_loss: 0.3536 - val_accuracy: 0.8870 - lr: 1.8530e-05\n",
      "Epoch 22/40\n",
      "897/897 [==============================] - 61s 68ms/step - loss: 0.2257 - accuracy: 0.9325 - val_loss: 0.3416 - val_accuracy: 0.8930 - lr: 1.6677e-05\n",
      "Epoch 23/40\n",
      "897/897 [==============================] - 59s 66ms/step - loss: 0.2207 - accuracy: 0.9368 - val_loss: 0.3442 - val_accuracy: 0.8908 - lr: 1.5009e-05\n",
      "Epoch 24/40\n",
      "897/897 [==============================] - 58s 65ms/step - loss: 0.2137 - accuracy: 0.9375 - val_loss: 0.3412 - val_accuracy: 0.8927 - lr: 1.3509e-05\n",
      "Epoch 25/40\n",
      "897/897 [==============================] - 60s 66ms/step - loss: 0.2115 - accuracy: 0.9393 - val_loss: 0.3383 - val_accuracy: 0.8949 - lr: 1.2158e-05\n",
      "Epoch 26/40\n",
      "897/897 [==============================] - 61s 67ms/step - loss: 0.2049 - accuracy: 0.9423 - val_loss: 0.3285 - val_accuracy: 0.8999 - lr: 1.0942e-05\n",
      "Epoch 27/40\n",
      "897/897 [==============================] - 58s 65ms/step - loss: 0.2014 - accuracy: 0.9445 - val_loss: 0.3302 - val_accuracy: 0.8968 - lr: 9.8477e-06\n",
      "Epoch 28/40\n",
      "897/897 [==============================] - 59s 66ms/step - loss: 0.1987 - accuracy: 0.9447 - val_loss: 0.3214 - val_accuracy: 0.9002 - lr: 8.8629e-06\n",
      "Epoch 29/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.1958 - accuracy: 0.9458 - val_loss: 0.3241 - val_accuracy: 0.9012 - lr: 7.9766e-06\n",
      "Epoch 30/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.1918 - accuracy: 0.9478 - val_loss: 0.3203 - val_accuracy: 0.9056 - lr: 7.1790e-06\n",
      "Epoch 31/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.1894 - accuracy: 0.9488 - val_loss: 0.3198 - val_accuracy: 0.9040 - lr: 6.4611e-06\n",
      "Epoch 32/40\n",
      "897/897 [==============================] - 59s 66ms/step - loss: 0.1867 - accuracy: 0.9497 - val_loss: 0.3211 - val_accuracy: 0.9052 - lr: 5.8150e-06\n",
      "Epoch 33/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.1854 - accuracy: 0.9507 - val_loss: 0.3162 - val_accuracy: 0.9062 - lr: 5.2335e-06\n",
      "Epoch 34/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.1824 - accuracy: 0.9514 - val_loss: 0.3187 - val_accuracy: 0.9062 - lr: 4.7101e-06\n",
      "Epoch 35/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.1804 - accuracy: 0.9522 - val_loss: 0.3198 - val_accuracy: 0.9074 - lr: 4.2391e-06\n",
      "Epoch 36/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.1797 - accuracy: 0.9527 - val_loss: 0.3144 - val_accuracy: 0.9065 - lr: 3.8152e-06\n",
      "Epoch 37/40\n",
      "897/897 [==============================] - 60s 67ms/step - loss: 0.1792 - accuracy: 0.9526 - val_loss: 0.3136 - val_accuracy: 0.9071 - lr: 3.4337e-06\n",
      "Epoch 38/40\n",
      "897/897 [==============================] - 74s 83ms/step - loss: 0.1769 - accuracy: 0.9537 - val_loss: 0.3149 - val_accuracy: 0.9071 - lr: 3.0903e-06\n",
      "Epoch 39/40\n",
      "897/897 [==============================] - 74s 82ms/step - loss: 0.1775 - accuracy: 0.9539 - val_loss: 0.3155 - val_accuracy: 0.9068 - lr: 2.7813e-06\n",
      "Epoch 40/40\n",
      "897/897 [==============================] - 65s 73ms/step - loss: 0.1755 - accuracy: 0.9542 - val_loss: 0.3195 - val_accuracy: 0.9074 - lr: 2.5032e-06\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=40, validation_data=(X_test, y_test), batch_size=32, callbacks=[early_stopping, model_checkpoint, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 3s 27ms/step - loss: 0.3136 - accuracy: 0.9071\n",
      "Test Loss: 0.31360960006713867\n",
      "Test Accuracy: 0.9071226716041565\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-29 18:04:24.142072: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-29 18:04:24.143891: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-29 18:04:24.145199: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n",
      "2024-05-29 18:04:24.316838: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2024-05-29 18:04:24.318179: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2024-05-29 18:04:24.319597: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100/100 [==============================] - 4s 31ms/step\n",
      "Predicted probabilities: [[0.00186843 0.9879489  0.01018265]\n",
      " [0.00248631 0.07083724 0.92667645]\n",
      " [0.9840941  0.0100226  0.00588315]\n",
      " [0.00155931 0.98752207 0.01091862]\n",
      " [0.97370756 0.01863698 0.00765539]\n",
      " [0.00638556 0.9858951  0.00771951]\n",
      " [0.00246102 0.04474273 0.9527963 ]\n",
      " [0.00226001 0.9757517  0.02198827]\n",
      " [0.335406   0.06722655 0.59736735]\n",
      " [0.00185423 0.9877922  0.01035354]]\n",
      "Actual labels: [[0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n",
      "                                                Text  Actual Class  \\\n",
      "0  international leads consumer gainers nio tata ...             1   \n",
      "1         pleased bjorn wahlroos accepted nomination             2   \n",
      "2  us energy information administration projects ...             0   \n",
      "3  edited transcript earnings conference call pre...             1   \n",
      "4  okmetic expects net sales first half 2009 less...             0   \n",
      "5  universities pledged set questions hit strike ...             1   \n",
      "6            company market share continued increase             2   \n",
      "7  mhi selected inclusion four esg investment ind...             1   \n",
      "8       stocks dow 70483 points nasdaq 16539 sp 7215             2   \n",
      "9  ms responsible hkscan hr functions development...             1   \n",
      "\n",
      "   Predicted Class                 Predicted Probabilities  \n",
      "0                1  [0.0018684333, 0.9879489, 0.010182653]  \n",
      "1                2  [0.0024863118, 0.07083724, 0.92667645]  \n",
      "2                0   [0.9840941, 0.010022602, 0.005883146]  \n",
      "3                1  [0.0015593101, 0.98752207, 0.01091862]  \n",
      "4                0  [0.97370756, 0.018636977, 0.007655388]  \n",
      "5                1  [0.0063855634, 0.9858951, 0.007719506]  \n",
      "6                2  [0.0024610157, 0.044742726, 0.9527963]  \n",
      "7                1  [0.0022600084, 0.9757517, 0.021988269]  \n",
      "8                2      [0.335406, 0.06722655, 0.59736735]  \n",
      "9                1  [0.0018542319, 0.9877922, 0.010353543]  \n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}\")\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "\n",
    "# Get predicted probabilities\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Print some example predictions\n",
    "print(\"Predicted probabilities:\", predictions[:10])\n",
    "print(\"Actual labels:\", y_test[:10])\n",
    "\n",
    "# Convert one-hot encoded y_test back to class labels for comparison\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Create a DataFrame to compare predictions with actual values\n",
    "results_df = pd.DataFrame({\n",
    "    'Text': [\" \".join([token.index_word.get(idx, \"\") for idx in x if idx != 0]) for x in X_test],\n",
    "    'Actual Class': true_classes,\n",
    "    'Predicted Class': np.argmax(predictions, axis=1),\n",
    "    'Predicted Probabilities': list(predictions)\n",
    "})\n",
    "\n",
    "# Show the DataFrame\n",
    "print(results_df.head(10))\n",
    "\n",
    "# Save results\n",
    "results_df['sentiment_score'] = results_df['Predicted Probabilities'].apply(lambda x: -1 * x[0] + 1 * x[2])\n",
    "results_df.to_excel(\"scores.xlsx\")\n",
    "\n",
    "# Save model and tokenizer\n",
    "model.save(\"sentimentModel_word2vec_lstm.keras\")\n",
    "with open('tokenizer_word2vec.pickle', 'wb') as handle:\n",
    "    pickle.dump(token, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df['sentiment_score'] = results_df['Predicted Probabilities'].apply(lambda x: -1 * x[0] + 1 * x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_excel(\"scores_lstm_word2vec.xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"all-data-processed.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Clean sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The core of Solidium 's investment strategy is...</td>\n",
       "      <td>core solidium investment strategy proper value...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1</td>\n",
       "      <td>`` The implementation of these programs has ha...</td>\n",
       "      <td>implementation programs negative impacts 2006 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>ADPnews - Aug 3 , 2009 - Finnish media group I...</td>\n",
       "      <td>adpnews aug 3 2009 finnish media group ilkkayh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1</td>\n",
       "      <td>Operating loss amounted to EUR 0.9 mn in the f...</td>\n",
       "      <td>operating loss amounted eur 09 mn first half 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>TomTom has given assurances that it will conti...</td>\n",
       "      <td>tomtom given assurances continue sell maps com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2721</th>\n",
       "      <td>1</td>\n",
       "      <td>Via the Satlan acquisition , Teleste plans to ...</td>\n",
       "      <td>via satlan acquisition teleste plans expand ma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2722</th>\n",
       "      <td>-1</td>\n",
       "      <td>However , the growth margin slowed down due to...</td>\n",
       "      <td>however growth margin slowed due financial crisis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>1</td>\n",
       "      <td>Outotec 's net profit for the second quarter o...</td>\n",
       "      <td>outotec net profit second quarter 2007 jumped ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2724</th>\n",
       "      <td>1</td>\n",
       "      <td>The restructuring creates a more efficient org...</td>\n",
       "      <td>restructuring creates efficient organization i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2725</th>\n",
       "      <td>1</td>\n",
       "      <td>Finlan 's listed food industry company HKScan ...</td>\n",
       "      <td>finlan listed food industry company hkscan gro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2726 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment                                           Sentence  \\\n",
       "0             1  The core of Solidium 's investment strategy is...   \n",
       "1            -1  `` The implementation of these programs has ha...   \n",
       "2            -1  ADPnews - Aug 3 , 2009 - Finnish media group I...   \n",
       "3            -1  Operating loss amounted to EUR 0.9 mn in the f...   \n",
       "4             1  TomTom has given assurances that it will conti...   \n",
       "...         ...                                                ...   \n",
       "2721          1  Via the Satlan acquisition , Teleste plans to ...   \n",
       "2722         -1  However , the growth margin slowed down due to...   \n",
       "2723          1  Outotec 's net profit for the second quarter o...   \n",
       "2724          1  The restructuring creates a more efficient org...   \n",
       "2725          1  Finlan 's listed food industry company HKScan ...   \n",
       "\n",
       "                                        Clean sentences  \n",
       "0     core solidium investment strategy proper value...  \n",
       "1     implementation programs negative impacts 2006 ...  \n",
       "2     adpnews aug 3 2009 finnish media group ilkkayh...  \n",
       "3     operating loss amounted eur 09 mn first half 2...  \n",
       "4     tomtom given assurances continue sell maps com...  \n",
       "...                                                 ...  \n",
       "2721  via satlan acquisition teleste plans expand ma...  \n",
       "2722  however growth margin slowed due financial crisis  \n",
       "2723  outotec net profit second quarter 2007 jumped ...  \n",
       "2724  restructuring creates efficient organization i...  \n",
       "2725  finlan listed food industry company hkscan gro...  \n",
       "\n",
       "[2726 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2453,), (273,), (2453,), (273,))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"Clean sentences\"], data[\"Sentiment\"], test_size=0.1, random_state=42)\n",
    "X_train.shape , X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenizing (str to int conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size=5656\n",
      "Number of Documents=2453\n"
     ]
    }
   ],
   "source": [
    "vocab = len(token.index_word) + 1\n",
    "print(\"Vocabulary size={}\".format(len(token.word_index)))\n",
    "print(\"Number of Documents={}\".format(token.document_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = token.texts_to_sequences(X_train)\n",
    "X_test = token.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2453, 30), (273, 30))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 30\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adam/.local/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/home/adam/.local/lib/python3.10/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "num_classes=2 # positive -> 1, negative -> 0\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_8 (Embedding)     (None, 30, 300)           1697100   \n",
      "                                                                 \n",
      " conv1d_8 (Conv1D)           (None, 23, 64)            153664    \n",
      "                                                                 \n",
      " max_pooling1d_3 (MaxPooling  (None, 11, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_19 (Dropout)        (None, 11, 64)            0         \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 11, 8)             520       \n",
      "                                                                 \n",
      " dropout_20 (Dropout)        (None, 11, 8)             0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 11, 4)             36        \n",
      "                                                                 \n",
      " dropout_21 (Dropout)        (None, 11, 4)             0         \n",
      "                                                                 \n",
      " global_max_pooling1d_8 (Glo  (None, 4)                0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,851,325\n",
      "Trainable params: 1,851,325\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout,MaxPooling1D\n",
    "\n",
    "\n",
    "vec_size = 300\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(token.index_word) + 1, vec_size, input_length=30))\n",
    "model.add(Conv1D(64,8, activation=\"relu\"))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer=tf.optimizers.Adam(learning_rate=0.0001), metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "550/552 [============================>.] - ETA: 0s - loss: 0.6618 - accuracy: 0.7432\n",
      "Epoch 1: val_accuracy improved from -inf to 0.81301, saving model to ./best_model/best_model_cnn1d.h5\n",
      "552/552 [==============================] - 14s 26ms/step - loss: 0.6616 - accuracy: 0.7431 - val_loss: 0.6246 - val_accuracy: 0.8130\n",
      "Epoch 2/100\n",
      "550/552 [============================>.] - ETA: 0s - loss: 0.4932 - accuracy: 0.8964\n",
      "Epoch 2: val_accuracy improved from 0.81301 to 0.89431, saving model to ./best_model/best_model_cnn1d.h5\n",
      "552/552 [==============================] - 14s 25ms/step - loss: 0.4927 - accuracy: 0.8962 - val_loss: 0.3975 - val_accuracy: 0.8943\n",
      "Epoch 3/100\n",
      "551/552 [============================>.] - ETA: 0s - loss: 0.2290 - accuracy: 0.9574\n",
      "Epoch 3: val_accuracy improved from 0.89431 to 0.91870, saving model to ./best_model/best_model_cnn1d.h5\n",
      "552/552 [==============================] - 13s 24ms/step - loss: 0.2289 - accuracy: 0.9574 - val_loss: 0.2734 - val_accuracy: 0.9187\n",
      "Epoch 4/100\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9814\n",
      "Epoch 4: val_accuracy did not improve from 0.91870\n",
      "552/552 [==============================] - 14s 26ms/step - loss: 0.0992 - accuracy: 0.9814 - val_loss: 0.2283 - val_accuracy: 0.9146\n",
      "Epoch 5/100\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0492 - accuracy: 0.9928\n",
      "Epoch 5: val_accuracy did not improve from 0.91870\n",
      "552/552 [==============================] - 14s 26ms/step - loss: 0.0492 - accuracy: 0.9928 - val_loss: 0.2162 - val_accuracy: 0.9187\n",
      "Epoch 6/100\n",
      "551/552 [============================>.] - ETA: 0s - loss: 0.0306 - accuracy: 0.9941\n",
      "Epoch 6: val_accuracy did not improve from 0.91870\n",
      "552/552 [==============================] - 13s 23ms/step - loss: 0.0306 - accuracy: 0.9941 - val_loss: 0.2116 - val_accuracy: 0.9187\n",
      "Epoch 7/100\n",
      "551/552 [============================>.] - ETA: 0s - loss: 0.0192 - accuracy: 0.9964\n",
      "Epoch 7: val_accuracy improved from 0.91870 to 0.92683, saving model to ./best_model/best_model_cnn1d.h5\n",
      "552/552 [==============================] - 13s 23ms/step - loss: 0.0192 - accuracy: 0.9964 - val_loss: 0.2290 - val_accuracy: 0.9268\n",
      "Epoch 8/100\n",
      "550/552 [============================>.] - ETA: 0s - loss: 0.0120 - accuracy: 0.9995\n",
      "Epoch 8: val_accuracy did not improve from 0.92683\n",
      "552/552 [==============================] - 12s 22ms/step - loss: 0.0120 - accuracy: 0.9995 - val_loss: 0.2214 - val_accuracy: 0.9228\n",
      "Epoch 9/100\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9977\n",
      "Epoch 9: val_accuracy did not improve from 0.92683\n",
      "552/552 [==============================] - 14s 25ms/step - loss: 0.0091 - accuracy: 0.9977 - val_loss: 0.2355 - val_accuracy: 0.9146\n",
      "Epoch 10/100\n",
      "551/552 [============================>.] - ETA: 0s - loss: 0.0055 - accuracy: 1.0000\n",
      "Epoch 10: val_accuracy did not improve from 0.92683\n",
      "552/552 [==============================] - 11s 21ms/step - loss: 0.0055 - accuracy: 1.0000 - val_loss: 0.2407 - val_accuracy: 0.9146\n",
      "Epoch 11/100\n",
      "552/552 [==============================] - ETA: 0s - loss: 0.0051 - accuracy: 0.9995\n",
      "Epoch 11: val_accuracy did not improve from 0.92683\n",
      "552/552 [==============================] - 11s 21ms/step - loss: 0.0051 - accuracy: 0.9995 - val_loss: 0.2628 - val_accuracy: 0.9187\n",
      "Epoch 11: early stopping\n"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "batch_size = 4\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "mc = ModelCheckpoint('./best_model/best_model_cnn1d.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
    "history = model.fit(X_train, y_train,  batch_size=batch_size, shuffle=True, validation_split=0.1, epochs=epochs, verbose=1, callbacks=[es, mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(x):\n",
    "    prediction_probs = model.predict(x)\n",
    "    predictions = [1 if prob > 0.5 else 0 for prob in prediction_probs]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(X_test).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = {v: k for k, v in token.word_index.items()}\n",
    "\n",
    "def sequences_to_texts(sequences):\n",
    "    texts = []\n",
    "    for sequence in sequences:\n",
    "        texts.append(' '.join([reverse_word_index.get(i, '?') for i in sequence]))\n",
    "    return texts\n",
    "\n",
    "test_phrases = sequences_to_texts(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Phrase  Actual Sentiment  \\\n",
      "0  two companies also partner developing lowering...                 1   \n",
      "1  three year turnaround program expected ensure ...                 1   \n",
      "2  finnish plumbing heating systems supplier upon...                 0   \n",
      "3  finnish meat company atria longer promise suff...                 0   \n",
      "4  driver left car suspect kidnapped forced gunpo...                 0   \n",
      "5  third original participants dropped due nausea...                 0   \n",
      "6  finland snow storms brought trees power lines ...                 0   \n",
      "7  finnish raisio diagnostics launching new ensur...                 1   \n",
      "8  able 20 russian market advertising press purch...                 1   \n",
      "9  broker initiated ag konecranes oyj buy 51 42 e...                 1   \n",
      "\n",
      "   Predicted Probability  \n",
      "0               0.997617  \n",
      "1               0.999961  \n",
      "2               0.004546  \n",
      "3               0.000468  \n",
      "4               0.002802  \n",
      "5               0.000121  \n",
      "6               0.003278  \n",
      "7               0.999768  \n",
      "8               0.999616  \n",
      "9               0.997672  \n"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Phrase': test_phrases,\n",
    "    'Actual Sentiment': y_test.flatten(),\n",
    "    'Predicted Probability': predictions\n",
    "})\n",
    "\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "                                            Headline  Predicted Probability  \\\n",
      "0  Stock markets rally as economy shows signs of ...               0.998472   \n",
      "1  Severe weather warnings issued across the country               0.171261   \n",
      "2  Tech companies report record earnings this qua...               0.989551   \n",
      "\n",
      "   Predicted Sentiment  \n",
      "0                    1  \n",
      "1                   -1  \n",
      "2                    1  \n"
     ]
    }
   ],
   "source": [
    "new_headlines = [\n",
    "    \"Stock markets rally as economy shows signs of recovery\",\n",
    "    \"Severe weather warnings issued across the country\",\n",
    "    \"Tech companies report record earnings this quarter\"\n",
    "]\n",
    "\n",
    "# Tokenize and pad the new headlines\n",
    "sequences = token.texts_to_sequences(new_headlines)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=30, padding='post', truncating='post')\n",
    "\n",
    "# Make predictions\n",
    "new_predictions = model.predict(padded_sequences)\n",
    "new_predictions = new_predictions.flatten()  # Flatten if needed\n",
    "\n",
    "# Convert probabilities to class labels if needed (for visualization)\n",
    "predicted_classes = (new_predictions > 0.5).astype(\"int32\")\n",
    "predicted_classes = np.where(predicted_classes == 0, -1, 1)\n",
    "\n",
    "# Create DataFrame\n",
    "new_results_df = pd.DataFrame({\n",
    "    'Headline': new_headlines,\n",
    "    'Predicted Probability': new_predictions,\n",
    "    'Predicted Sentiment': predicted_classes\n",
    "})\n",
    "\n",
    "# Show the DataFrame\n",
    "print(new_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

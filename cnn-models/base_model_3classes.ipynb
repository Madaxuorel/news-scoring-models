{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 10:54:50.184006: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-27 10:54:50.228857: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-27 10:54:50.229831: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-27 10:54:51.090962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"all-data-processed-3classes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Clean sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>In Finland 's Hobby Hall 's sales decreased by...</td>\n",
       "      <td>finland hobby hall sales decreased 10 internat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Panostaja did not disclose the purchase price .</td>\n",
       "      <td>panostaja disclose purchase price</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1</td>\n",
       "      <td>Scanfil will execute the temporary lay-offs by...</td>\n",
       "      <td>scanfil execute temporary layoffs midoctober 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Operating profit rose to EUR 13.1 mn from EUR ...</td>\n",
       "      <td>operating profit rose eur 131 mn eur 87 mn cor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>The company 's share is quoted on NASDAQ OMX H...</td>\n",
       "      <td>company share quoted nasdaq omx helsinki rauta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8632</th>\n",
       "      <td>0</td>\n",
       "      <td>In addition to the presentations held by Presi...</td>\n",
       "      <td>addition presentations held president ceo kai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8633</th>\n",
       "      <td>1</td>\n",
       "      <td>However , the broker gave an `` outperform '' ...</td>\n",
       "      <td>however broker gave outperform recommendation ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8634</th>\n",
       "      <td>0</td>\n",
       "      <td>Tampere Science Parks is a Finnish company tha...</td>\n",
       "      <td>tampere science parks finnish company owns lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8635</th>\n",
       "      <td>0</td>\n",
       "      <td>Aldata noted that its Voice Supply Chain Techn...</td>\n",
       "      <td>aldata noted voice supply chain technology app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8636</th>\n",
       "      <td>1</td>\n",
       "      <td>In the reporting period , the company 's opera...</td>\n",
       "      <td>reporting period company operating profit grew...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8637 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sentiment                                           Sentence  \\\n",
       "0            -1  In Finland 's Hobby Hall 's sales decreased by...   \n",
       "1             0    Panostaja did not disclose the purchase price .   \n",
       "2            -1  Scanfil will execute the temporary lay-offs by...   \n",
       "3             1  Operating profit rose to EUR 13.1 mn from EUR ...   \n",
       "4             0  The company 's share is quoted on NASDAQ OMX H...   \n",
       "...         ...                                                ...   \n",
       "8632          0  In addition to the presentations held by Presi...   \n",
       "8633          1  However , the broker gave an `` outperform '' ...   \n",
       "8634          0  Tampere Science Parks is a Finnish company tha...   \n",
       "8635          0  Aldata noted that its Voice Supply Chain Techn...   \n",
       "8636          1  In the reporting period , the company 's opera...   \n",
       "\n",
       "                                        Clean sentences  \n",
       "0     finland hobby hall sales decreased 10 internat...  \n",
       "1                     panostaja disclose purchase price  \n",
       "2     scanfil execute temporary layoffs midoctober 2...  \n",
       "3     operating profit rose eur 131 mn eur 87 mn cor...  \n",
       "4     company share quoted nasdaq omx helsinki rauta...  \n",
       "...                                                 ...  \n",
       "8632  addition presentations held president ceo kai ...  \n",
       "8633  however broker gave outperform recommendation ...  \n",
       "8634  tampere science parks finnish company owns lea...  \n",
       "8635  aldata noted voice supply chain technology app...  \n",
       "8636  reporting period company operating profit grew...  \n",
       "\n",
       "[8637 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7773,), (864,), (7773,), (864,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data[\"Clean sentences\"], data[\"Sentiment\"], test_size=0.1, random_state=42)\n",
    "X_train.shape , X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tokenizing (str to int conversion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4655    manager critical politicians failure different...\n",
       "7959    russia ready participate open tender latteleco...\n",
       "37      developments partly reflect government higher ...\n",
       "5761    sampo group become major shareholder nordea ow...\n",
       "8605    seawind en route finnish port turku stockholm ...\n",
       "                              ...                        \n",
       "5734    webcast may followed online company website ww...\n",
       "5191    according finnish scanfil founder chairman boa...\n",
       "5390    currency conversions based exchange rates time...\n",
       "860     thus method cut working costs fasten planning ...\n",
       "7270    omx helsinki 25 index 092 pct 251867 helsinki ...\n",
       "Name: Clean sentences, Length: 7773, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "token = Tokenizer()\n",
    "token.fit_on_texts(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size=10468\n",
      "Number of Documents=7773\n"
     ]
    }
   ],
   "source": [
    "vocab = len(token.index_word) + 1\n",
    "print(\"Vocabulary size={}\".format(len(token.word_index)))\n",
    "print(\"Number of Documents={}\".format(token.document_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = token.texts_to_sequences(X_train)\n",
    "X_test = token.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_lengths = [len(seq) for seq in X_train]\n",
    "\n",
    "# Find the maximum length\n",
    "max_length = max(sequence_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7773, 47), (864, 47))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAX_SEQUENCE_LENGTH = 47\n",
    "X_train = pad_sequences(X_train, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "X_test = pad_sequences(X_test, maxlen=MAX_SEQUENCE_LENGTH, padding=\"post\")\n",
    "X_train.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 2, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "y_train_labels = np.array(y_train)  # Convert to NumPy array if not already\n",
    "y_test_labels = np.array(y_test)  # Convert to NumPy array if not already"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.where(y_train_labels == -1, 0, y_train)\n",
    "y_train = np.where(y_train_labels == 0, 1, y_train)\n",
    "y_train = np.where(y_train_labels == 1, 2, y_train)\n",
    "\n",
    "y_test = np.where(y_test_labels == -1, 0, y_test)\n",
    "y_test = np.where(y_test_labels == 0, 1, y_test)\n",
    "y_test = np.where(y_test_labels == 1, 2, y_test)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=3)\n",
    "y_test = to_categorical(y_test, num_classes=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (None, 47, 300)           3140700   \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 40, 64)            153664    \n",
      "                                                                 \n",
      " max_pooling1d_2 (MaxPooling  (None, 20, 64)           0         \n",
      " 1D)                                                             \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 20, 64)            0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 20, 8)             520       \n",
      "                                                                 \n",
      " dropout_7 (Dropout)         (None, 20, 8)             0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 20, 4)             36        \n",
      "                                                                 \n",
      " dropout_8 (Dropout)         (None, 20, 4)             0         \n",
      "                                                                 \n",
      " global_max_pooling1d_2 (Glo  (None, 4)                0         \n",
      " balMaxPooling1D)                                                \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 1)                 5         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,294,925\n",
      "Trainable params: 3,294,925\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout,MaxPooling1D\n",
    "import tensorflow as tf\n",
    "\n",
    "vec_size = 300\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(token.index_word) + 1, vec_size, input_length=max_length))\n",
    "model.add(Conv1D(64, 8, activation=\"relu\"))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.1))\n",
    "\n",
    "model.add(Dense(8, activation=\"relu\"))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(Dense(4, activation='relu'))\n",
    "model.add(Dropout(0.1))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(1, activation='linear'))  # Output layer with linear activation\n",
    "\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=tf.optimizers.Adam(learning_rate=0.0001), metrics=['mae'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "243/243 [==============================] - 10s 42ms/step - loss: 0.3044 - mae: 0.3489 - val_loss: 0.2980 - val_mae: 0.3527\n",
      "Epoch 2/100\n",
      "243/243 [==============================] - 10s 43ms/step - loss: 0.2922 - mae: 0.3563 - val_loss: 0.2865 - val_mae: 0.3599\n",
      "Epoch 3/100\n",
      "243/243 [==============================] - 11s 47ms/step - loss: 0.2814 - mae: 0.3634 - val_loss: 0.2763 - val_mae: 0.3669\n",
      "Epoch 4/100\n",
      "243/243 [==============================] - 11s 44ms/step - loss: 0.2718 - mae: 0.3703 - val_loss: 0.2673 - val_mae: 0.3736\n",
      "Epoch 5/100\n",
      "243/243 [==============================] - 11s 47ms/step - loss: 0.2633 - mae: 0.3769 - val_loss: 0.2595 - val_mae: 0.3801\n",
      "Epoch 6/100\n",
      "243/243 [==============================] - 10s 43ms/step - loss: 0.2560 - mae: 0.3832 - val_loss: 0.2526 - val_mae: 0.3864\n",
      "Epoch 7/100\n",
      "243/243 [==============================] - 10s 42ms/step - loss: 0.2496 - mae: 0.3894 - val_loss: 0.2467 - val_mae: 0.3923\n",
      "Epoch 8/100\n",
      "243/243 [==============================] - 12s 50ms/step - loss: 0.2441 - mae: 0.3952 - val_loss: 0.2416 - val_mae: 0.3981\n",
      "Epoch 9/100\n",
      "243/243 [==============================] - 11s 46ms/step - loss: 0.2394 - mae: 0.4008 - val_loss: 0.2373 - val_mae: 0.4035\n",
      "Epoch 10/100\n",
      "243/243 [==============================] - 11s 44ms/step - loss: 0.2355 - mae: 0.4061 - val_loss: 0.2337 - val_mae: 0.4087\n",
      "Epoch 11/100\n",
      "243/243 [==============================] - 10s 43ms/step - loss: 0.2322 - mae: 0.4111 - val_loss: 0.2308 - val_mae: 0.4135\n",
      "Epoch 12/100\n",
      "243/243 [==============================] - 11s 45ms/step - loss: 0.2296 - mae: 0.4158 - val_loss: 0.2285 - val_mae: 0.4181\n",
      "Epoch 13/100\n",
      "243/243 [==============================] - 11s 45ms/step - loss: 0.2275 - mae: 0.4202 - val_loss: 0.2266 - val_mae: 0.4223\n",
      "Epoch 14/100\n",
      "243/243 [==============================] - 11s 44ms/step - loss: 0.2259 - mae: 0.4242 - val_loss: 0.2252 - val_mae: 0.4262\n",
      "Epoch 15/100\n",
      "243/243 [==============================] - 10s 42ms/step - loss: 0.2247 - mae: 0.4279 - val_loss: 0.2242 - val_mae: 0.4296\n",
      "Epoch 16/100\n",
      "243/243 [==============================] - 10s 40ms/step - loss: 0.2238 - mae: 0.4312 - val_loss: 0.2235 - val_mae: 0.4327\n",
      "Epoch 17/100\n",
      "243/243 [==============================] - 10s 42ms/step - loss: 0.2232 - mae: 0.4341 - val_loss: 0.2230 - val_mae: 0.4354\n",
      "Epoch 18/100\n",
      "243/243 [==============================] - 10s 43ms/step - loss: 0.2228 - mae: 0.4366 - val_loss: 0.2226 - val_mae: 0.4377\n",
      "Epoch 19/100\n",
      "243/243 [==============================] - 10s 43ms/step - loss: 0.2225 - mae: 0.4387 - val_loss: 0.2224 - val_mae: 0.4396\n",
      "Epoch 20/100\n",
      "243/243 [==============================] - 10s 40ms/step - loss: 0.2224 - mae: 0.4404 - val_loss: 0.2223 - val_mae: 0.4411\n",
      "Epoch 21/100\n",
      "243/243 [==============================] - 10s 41ms/step - loss: 0.2223 - mae: 0.4417 - val_loss: 0.2223 - val_mae: 0.4423\n",
      "Epoch 22/100\n",
      "243/243 [==============================] - 10s 43ms/step - loss: 0.2223 - mae: 0.4427 - val_loss: 0.2222 - val_mae: 0.4431\n",
      "Epoch 23/100\n",
      "243/243 [==============================] - 10s 43ms/step - loss: 0.2222 - mae: 0.4434 - val_loss: 0.2222 - val_mae: 0.4436\n",
      "Epoch 24/100\n",
      "243/243 [==============================] - 10s 42ms/step - loss: 0.2222 - mae: 0.4438 - val_loss: 0.2222 - val_mae: 0.4440\n",
      "Epoch 25/100\n",
      "243/243 [==============================] - 10s 40ms/step - loss: 0.2222 - mae: 0.4441 - val_loss: 0.2222 - val_mae: 0.4442\n",
      "Epoch 26/100\n",
      "243/243 [==============================] - 10s 40ms/step - loss: 0.2222 - mae: 0.4443 - val_loss: 0.2222 - val_mae: 0.4443\n",
      "Epoch 27/100\n",
      "243/243 [==============================] - 12s 49ms/step - loss: 0.2222 - mae: 0.4444 - val_loss: 0.2222 - val_mae: 0.4444\n",
      "Epoch 28/100\n",
      "243/243 [==============================] - 12s 48ms/step - loss: 0.2222 - mae: 0.4444 - val_loss: 0.2222 - val_mae: 0.4444\n",
      "Epoch 29/100\n",
      "243/243 [==============================] - 11s 45ms/step - loss: 0.2222 - mae: 0.4444 - val_loss: 0.2222 - val_mae: 0.4444\n",
      "Epoch 30/100\n",
      "243/243 [==============================] - 11s 47ms/step - loss: 0.2222 - mae: 0.4444 - val_loss: 0.2222 - val_mae: 0.4444\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "epochs = 100\n",
    "batch_size = 4\n",
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
    "\n",
    "# Train the model with callbacks\n",
    "history = model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), batch_size=32, callbacks=[early_stopping, model_checkpoint])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 6ms/step\n",
      "                                                  Text  Actual Class  \\\n",
      "2      department store sales improved 14 eur 10706 mn             2   \n",
      "10   stable outlook reflects nokia strong market po...             2   \n",
      "20     cost savings rise 20 mln eur year 2007 oko said             2   \n",
      "23   planned facility estimated cost around 814 mil...             2   \n",
      "27   sale healthcare trade business supports oriola...             2   \n",
      "..                                                 ...           ...   \n",
      "844  kesko agro lietuva agricultural machinery grai...             2   \n",
      "856  finnish food industry companies hk ruokatalo a...             2   \n",
      "860  company makes garden tools scissors consumer g...             2   \n",
      "861  loans used finance strategic investments shopp...             2   \n",
      "863  dirk jones head financial institutions client ...             2   \n",
      "\n",
      "     Predicted Class  Predicted Probability  \n",
      "2                  0               0.333212  \n",
      "10                 0               0.333212  \n",
      "20                 0               0.333212  \n",
      "23                 0               0.333212  \n",
      "27                 0               0.333212  \n",
      "..               ...                    ...  \n",
      "844                0               0.333212  \n",
      "856                0               0.333212  \n",
      "860                0               0.333212  \n",
      "861                0               0.333212  \n",
      "863                0               0.333212  \n",
      "\n",
      "[288 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Convert probabilities to class labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Convert one-hot encoded y_test back to class labels\n",
    "true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Create a DataFrame to compare predictions with actual values\n",
    "results_df = pd.DataFrame({\n",
    "    'Text': [\" \".join([token.index_word.get(idx, \"\") for idx in x if idx != 0]) for x in X_test],\n",
    "    'Actual Class': true_classes,\n",
    "    'Predicted Class': predicted_classes,\n",
    "    'Predicted Probability': np.max(predictions, axis=1)\n",
    "})\n",
    "\n",
    "# Show the DataFrame\n",
    "print(results_df.loc[results_df[\"Actual Class\"]==2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictions(x):\n",
    "    prediction_probs = model.predict(x)\n",
    "    predictions = [1 if prob > 0.5 else 0 for prob in prediction_probs]\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(X_test).iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = predictions.flatten() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reverse_word_index = {v: k for k, v in token.word_index.items()}\n",
    "\n",
    "def sequences_to_texts(sequences):\n",
    "    texts = []\n",
    "    for sequence in sequences:\n",
    "        texts.append(' '.join([reverse_word_index.get(i, '?') for i in sequence]))\n",
    "    return texts\n",
    "\n",
    "test_phrases = sequences_to_texts(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m results_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPhrase\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_phrases\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mActual Sentiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPredicted Probability\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictions\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(results_df\u001b[38;5;241m.\u001b[39mhead(\u001b[38;5;241m10\u001b[39m))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/frame.py:663\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    657\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    658\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    659\u001b[0m     )\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    662\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 663\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    665\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmrecords\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmrecords\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:493\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    489\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    490\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    491\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 493\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:118\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 118\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    120\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/internals/construction.py:666\u001b[0m, in \u001b[0;36m_extract_index\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    664\u001b[0m lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[1;32m    665\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 666\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll arrays must be of the same length\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    668\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[1;32m    669\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    670\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    671\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    'Phrase': test_phrases,\n",
    "    'Actual Sentiment': y_test.flatten(),\n",
    "    'Predicted Probability': predictions\n",
    "})\n",
    "\n",
    "print(results_df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "                                            Headline  Predicted Probability  \\\n",
      "0  Stock markets rally as economy shows signs of ...               0.998472   \n",
      "1  Severe weather warnings issued across the country               0.171261   \n",
      "2  Tech companies report record earnings this qua...               0.989551   \n",
      "\n",
      "   Predicted Sentiment  \n",
      "0                    1  \n",
      "1                   -1  \n",
      "2                    1  \n"
     ]
    }
   ],
   "source": [
    "new_headlines = [\n",
    "    \"Stock markets rally as economy shows signs of recovery\",\n",
    "    \"Severe weather warnings issued across the country\",\n",
    "    \"Tech companies report record earnings this quarter\"\n",
    "]\n",
    "\n",
    "# Tokenize and pad the new headlines\n",
    "sequences = token.texts_to_sequences(new_headlines)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=30, padding='post', truncating='post')\n",
    "\n",
    "# Make predictions\n",
    "new_predictions = model.predict(padded_sequences)\n",
    "new_predictions = new_predictions.flatten()  # Flatten if needed\n",
    "\n",
    "# Convert probabilities to class labels if needed (for visualization)\n",
    "predicted_classes = (new_predictions > 0.5).astype(\"int32\")\n",
    "predicted_classes = np.where(predicted_classes == 0, -1, 1)\n",
    "\n",
    "# Create DataFrame\n",
    "new_results_df = pd.DataFrame({\n",
    "    'Headline': new_headlines,\n",
    "    'Predicted Probability': new_predictions,\n",
    "    'Predicted Sentiment': predicted_classes\n",
    "})\n",
    "\n",
    "# Show the DataFrame\n",
    "print(new_results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
